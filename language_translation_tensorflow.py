# -*- coding: utf-8 -*-
"""Language_Translation_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fHqFuwqimTZzK1SaUF6uSAqqxnabRg9C
"""

import tensorflow as tf
import tensorflow_hub as hub
import unicodedata
import re
from IPython.display import Image

"""For the capstone project, we will use a language dataset from http://www.manythings.org/anki/ to build a neural translation model. This dataset consists of over 200,000 pairs of sentences in English and German. In order to make the training quicker, we will restrict to our dataset to 20,000 pairs. Feel free to change this if you wish - the size of the dataset used is not part of the grading rubric.

Your goal is to develop a neural translation model from English to German, making use of a pre-trained English word embedding module.

#### Import the data

The dataset is available for download as a zip file at the following link:

https://drive.google.com/open?id=1KczOciG7sYY7SB9UlBeRP1T9659b121Q

You should store the unzipped folder in Drive for use in this Colab notebook.
"""

# Run this cell to connect to your Drive folder

from google.colab import drive
drive.mount('/content/gdrive')

# Run this cell to load the dataset

NUM_EXAMPLES = 20000
data_examples = []
with open('/content/gdrive/MyDrive/Datasets coursera/deu.txt', 'r', encoding='utf8') as f:
    for line in f.readlines():
        if len(data_examples) < NUM_EXAMPLES:
            data_examples.append(line)
        else:
            break

# These functions preprocess English and German sentences

def unicode_to_ascii(s):
    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')

def preprocess_sentence(sentence):
    sentence = sentence.lower().strip()
    sentence = re.sub(r"ü", 'ue', sentence)
    sentence = re.sub(r"ä", 'ae', sentence)
    sentence = re.sub(r"ö", 'oe', sentence)
    sentence = re.sub(r'ß', 'ss', sentence)
    
    sentence = unicode_to_ascii(sentence)
    sentence = re.sub(r"([?.!,])", r" \1 ", sentence)
    sentence = re.sub(r"[^a-z?.!,']+", " ", sentence)
    sentence = re.sub(r'[" "]+', " ", sentence)
    
    return sentence.strip()

"""#### The custom translation model
The following is a schematic of the custom translation model architecture you will develop in this project.
"""

# Run this cell to download and view a schematic diagram for the neural translation model

!wget -q -O neural_translation_model.png --no-check-certificate "https://docs.google.com/uc?export=download&id=1XsS1VlXoaEo-RbYNilJ9jcscNZvsSPmd"
Image("neural_translation_model.png")

"""The custom model consists of an encoder RNN and a decoder RNN. The encoder takes words of an English sentence as input, and uses a pre-trained word embedding to embed the words into a 128-dimensional space. To indicate the end of the input sentence, a special end token (in the same 128-dimensional space) is passed in as an input. This token is a TensorFlow Variable that is learned in the training phase (unlike the pre-trained word embedding, which is frozen).

The decoder RNN takes the internal state of the encoder network as its initial state. A start token is passed in as the first input, which is embedded using a learned German word embedding. The decoder RNN then makes a prediction for the next German word, which during inference is then passed in as the following input, and this process is repeated until the special `<end>` token is emitted from the decoder.

## 1. Text preprocessing
* Create separate lists of English and German sentences, and preprocess them using the `preprocess_sentence` function provided for you above.
* Add a special `"<start>"` and `"<end>"` token to the beginning and end of every German sentence.
* Use the Tokenizer class from the `tf.keras.preprocessing.text` module to tokenize the German sentences, ensuring that no character filters are applied.
"""

data_examples[:5]

english_sentences, german_sentences = [], []
for i in range(len(data_examples)):
    a,b,c = data_examples[i].split('\t')
    english_sentences.append(preprocess_sentence(a))
    german_sentences.append('<start> '+preprocess_sentence(b)+' <end>')

german_sentences[3:7]

from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer(num_words = None, filters = '')

tokenizer.fit_on_texts(german_sentences)

german_sentence_sequence = tokenizer.texts_to_sequences(german_sentences)
print(german_sentence_sequence[3:7])

from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np
padded_sequences = np.array(pad_sequences(german_sentence_sequence, padding='post'))
padded_sequences.shape

"""## 2. Prepare the data

#### Load the embedding layer
As part of the dataset preproceessing for this project, you will use a pre-trained English word embedding module from TensorFlow Hub. The URL for the module is https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1.

This embedding takes a batch of text tokens in a 1-D tensor of strings as input. It then embeds the separate tokens into a 128-dimensional space. 

The code to load and test the embedding layer is provided for you below.

**NB:** this model can also be used as a sentence embedding module. The module will process each token by removing punctuation and splitting on spaces. It then averages the word embeddings over a sentence to give a single embedding vector. However, we will use it only as a word embedding module, and will pass each word in the input sentence as a separate token.
"""

# Load embedding module from Tensorflow Hub

embedding_layer = hub.KerasLayer("https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1", 
                                 output_shape=[128], input_shape=[], dtype=tf.string)

# Test the layer

embedding_layer(tf.constant(["these", "aren't", "the", "droids", "you're", "looking", "for"])).shape

"""You should now prepare the training and validation Datasets.

* Create a random training and validation set split of the data, reserving e.g. 20% of the data for validation (NB: each English dataset example is a single sentence string, and each German dataset example is a sequence of padded integer tokens).
* Load the training and validation sets into a tf.data.Dataset object, passing in a tuple of English and German data for both training and validation sets.
* Create a function to map over the datasets that splits each English sentence at spaces. Apply this function to both Dataset objects using the map method. 
"""

shuffled = np.random.permutation(padded_sequences.shape[0])
test_indeces = shuffled[:int(0.2*padded_sequences.shape[0])]
train_indeces = shuffled[int(0.2*padded_sequences.shape[0]):]

train_sentences, val_sentences = np.array(english_sentences)[train_indeces], np.array(english_sentences)[test_indeces]
train_sequences, val_sequences = padded_sequences[train_indeces], padded_sequences[test_indeces]
print(train_sentences.shape, train_sequences.shape)

train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_sequences))
test_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_sequences))
train_dataset.element_spec

# splitting on the basis of spaces
def split_on_space(sentence, sequence):
    s = tf.strings.split(sentence)
    return(s, sequence)

train_dataset = train_dataset.map(split_on_space)
test_dataset = test_dataset.map(split_on_space)
test_dataset.element_spec

# mapping using embedded layer
def embd_mapping(sentence, sequence):
    sentence_to_sequence = embedding_layer(sentence)
    return(sentence_to_sequence, sequence)
train_dataset = train_dataset.map(embd_mapping)
test_dataset = test_dataset.map(embd_mapping)

# filter the english sentences with more than or equal to 13 words
def len_filter(sentence, sequence):
    return(tf.shape(sentence)[0]<14)
train_filtered = train_dataset.filter(len_filter)
test_filtered = test_dataset.filter(len_filter)

test_filtered, train_filtered

# padding the tensors
def dynamic_padding(inp, min_size):
    zero = tf.zeros(shape=(min_size-tf.shape(inp)[0], 128))
    
    return tf.concat([inp, zero], axis=0)

# Pad only if necessary
def seq_pad(seq, vals):
    filter_size=13
    padded = tf.cond(tf.less(tf.shape(seq)[0], filter_size), true_fn=lambda: dynamic_padding(seq, filter_size), false_fn=lambda: seq) 
    return(padded, vals)
dataset_test = test_filtered.map(seq_pad)
dataset_test.element_spec

dataset_train = train_filtered.map(seq_pad)
dataset_train.element_spec

# batching the dataset
train_dataset = dataset_train.batch(16, drop_remainder=True)
test_dataset = dataset_test.batch(16, drop_remainder=True)
print(train_dataset.element_spec)
print(test_dataset.element_spec)

example = train_dataset.take(1)
l = list(example.as_numpy_iterator())
for i in l:
    a,b = i
    print('english sequence shape: {}\n german sequence shape: {}'.format(a.shape,b.shape))

"""## 3. Create the custom layer
You will now create a custom layer to add the learned end token embedding to the encoder model:
"""

# Run this cell to download and view a schematic diagram for the encoder model

!wget -q -O neural_translation_model.png --no-check-certificate "https://docs.google.com/uc?export=download&id=1JrtNOzUJDaOWrK4C-xv-4wUuZaI12sQI"
Image("neural_translation_model.png")

"""You should now build the custom layer.
* Using layer subclassing, create a custom layer that takes a batch of English data examples from one of the Datasets, and adds a learned embedded ‘end’ token to the end of each sequence. 
* This layer should create a TensorFlow Variable (that will be learned during training) that is 128-dimensional (the size of the embedding space). _Hint: you may find it helpful in the call method to use the tf.tile function to replicate the end token embedding across every element in the batch._
* Using the Dataset `.take(1)` method, extract a batch of English data examples from the training Dataset and print the shape. Test the custom layer by calling the layer on the English data batch Tensor and print the resulting Tensor shape (the layer should increase the sequence length by one).
"""

from tensorflow.keras.layers import Layer
class myLayer(Layer):
    def __init__(self, units = 1):    # units is the number of tokens to add at end
        super(myLayer, self).__init__()
        self.units = units
    
    def build(self, input_shape):
        end_init = tf.random_normal_initializer()
        self.end = tf.Variable(name = 'end_token', initial_value= end_init(shape = (input_shape[0],self.units, input_shape[-1]), dtype = 'float32'), trainable=True)

    def call(self, inputs):
        return tf.concat([inputs, self.end], axis=1)

custom_layer = myLayer(units=1)
for elem in example:
    a,b = elem
    c = custom_layer(a)
    print(tf.shape(c))

custom_layer.variables

"""## 4. Build the encoder network
The encoder network follows the schematic diagram above. You should now build the RNN encoder model.
* Using the functional API, build the encoder network.
"""

from tensorflow.keras.layers import Dense, LSTM, Masking, Input
from tensorflow.keras.models import Model

inp = Input(shape=(13,128), batch_size = 16)
x = myLayer(units=1)(inp)
x = Masking(mask_value=0.0)(x)
out = LSTM(512, return_state=True)(x)
encoder = Model(inputs = inp, outputs = out)
encoder.summary()

for elem in example:
    a,b = elem
    out, hid_state, cell_state = encoder(a)
    print(tf.shape(out), tf.shape(hid_state), tf.shape(cell_state))

"""## 5. Build the decoder network
The decoder network follows the schematic diagram below. 
"""

# Run this cell to download and view a schematic diagram for the decoder model

!wget -q -O neural_translation_model.png --no-check-certificate "https://docs.google.com/uc?export=download&id=1DTeaXD8tA8RjkpVrB2mr9csSBOY4LQiW"
Image("neural_translation_model.png")

"""You should now build the RNN decoder model.
* Using Model subclassing, build the decoder network according to the following spec:
    * The initializer should create the following layers:
        * An Embedding layer with vocabulary size set to the number of unique German tokens, embedding dimension 128, and set to mask zero values in the input.
        * An LSTM layer with 512 units, that returns its hidden and cell states, and also returns sequences.
        * A Dense layer with number of units equal to the number of unique German tokens, and no activation function.
    * The call method should include the usual `inputs` argument, as well as the additional keyword arguments `hidden_state` and `cell_state`. The default value for these keyword arguments should be `None`.
    * The call method should pass the inputs through the Embedding layer, and then through the LSTM layer. If the `hidden_state` and `cell_state` arguments are provided, these should be used for the initial state of the LSTM layer. _Hint: use the_ `initial_state` _keyword argument when calling the LSTM layer on its input._
    * The call method should pass the LSTM output sequence through the Dense layer, and return the resulting Tensor, along with the hidden and cell states of the LSTM layer.
* Using the Dataset `.take(1)` method, extract a batch of English and German data examples from the training Dataset. Test the decoder model by first calling the encoder model on the English data Tensor to get the hidden and cell states, and then call the decoder model on the German data Tensor and hidden and cell states, and print the shape of the resulting decoder Tensor outputs.
* Print the model summary for the decoder network.
"""

from tensorflow.keras.layers import Embedding
import json
tokenizer_config = tokenizer.get_config()
word_index = json.loads(tokenizer_config['word_index'])
max_index = max(list(word_index.values()))
max_index

from tensorflow.keras.models import Sequential
from tensorflow.keras import Model

class Decoder(Model):
    def __init__(self, units = max_index, **kwargs):
        super().__init__(**kwargs)
        self.units = units
        self.embd = Embedding(self.units+1, 128, mask_zero=True)
        self.lstm = LSTM(512)
        self.dense = Dense(self.units)
    
    def call(self, inputs, hidden_state = None, cell_state = None):
        inp = self.embd(inputs)
        if hidden_state is not None and cell_state is not None: 
            x = self.lstm(inp, initial_state = [hidden_state, cell_state])
        else:
            x = self.lstm(inp)
        out = self.dense(x)
        return(out)

decoder = Decoder()

# Testing the decoder model
for elem in example:
    a,b = elem
    out1, hid_state, cell_state = encoder(a)
    print(tf.shape(out1))
    out2 = decoder(b, hid_state, cell_state)
    print(tf.shape(out2))

decoder.summary()

"""## 6. Make a custom training loop
You should now write a custom training loop to train your custom neural translation model.
* Define a function that takes a Tensor batch of German data (as extracted from the training Dataset), and returns a tuple containing German inputs and outputs for the decoder model (refer to schematic diagram above).
* Define a function that computes the forward and backward pass for your translation model. This function should take an English input, German input and German output as arguments, and should do the following:
    * Pass the English input into the encoder, to get the hidden and cell states of the encoder LSTM.
    * These hidden and cell states are then passed into the decoder, along with the German inputs, which returns a sequence of outputs (the hidden and cell state outputs of the decoder LSTM are unused in this function).
    * The loss should then be computed between the decoder outputs and the German output function argument.
    * The function returns the loss and gradients with respect to the encoder and decoder’s trainable variables.
    * Decorate the function with `@tf.function`
* Define and run a custom training loop for a number of epochs (for you to choose) that does the following:
    * Iterates through the training dataset, and creates decoder inputs and outputs from the German sequences.
    * Updates the parameters of the translation model using the gradients of the function above and an optimizer object.
    * Every epoch, compute the validation loss on a number of batches from the validation and save the epoch training and validation losses.
* Plot the learning curves for loss vs epoch for both training and validation sets.

_Hint: This model is computationally demanding to train. The quality of the model or length of training is not a factor in the grading rubric. However, to obtain a better model we recommend using the GPU accelerator hardware on Colab._
"""

def german_out_func(german_seq_dataset):
    return(decoder(german_seq_dataset))

def decoder_outputs(elements):
    a,b = elements
    out1, hid_state, cell_state = encoder(a)
    out2 = decoder(b, hid_state, cell_state)
    return(out2)

@tf.function
def loss_and_grad(elem):
    a,b = elem
    with tf.GradientTape(persistent=True) as tape:
        out1 = german_out_func(b)
        out2 = decoder_outputs(elem)
        loss_val = tf.keras.losses.mse(out1, out2)
    gradients_decoder = tape.gradient(loss_val, decoder.trainable_variables)
    gradients_encoder = tape.gradient(loss_val, encoder.trainable_variables)
    return(loss_val, gradients_decoder, gradients_encoder)

optimizer = tf.keras.optimizers.Adam()
epochs = 3
val_losses, train_losses = [], []

for epoch in range(epochs):
    print('Start of %d epoch'%(epoch,))
    losses = []
    for elem in train_dataset:
        loss, gradients_decoder, gradients_encoder = loss_and_grad(elem)
        losses.append(loss)
        optimizer.apply_gradients(zip(gradients_decoder, decoder.trainable_variables))
        optimizer.apply_gradients(zip(gradients_encoder, encoder.trainable_variables))
    train_losses.append(np.mean(losses))
    print('\t loss: ', train_losses[-1])
    val_loss = []
    for elem in test_dataset:
        loss, gradients_decoder, gradients_encoder = loss_and_grad(elem)
        val_loss.append(loss)
    val_losses.append(np.mean(val_loss))
    print('\t validation loss', val_losses[-1])

# Visualisation
import matplotlib.pyplot as plt

plt.plot(list(range(1,epochs+1)),train_losses, label = 'Train loss')
plt.plot(list(range(1, epochs)), val_losses, label = 'Validation_loss')
plt.legend()
plt.xlabel('epochs')
plt.ylabel('loss')
plt.title('Variation of mean squared error')
plt.show()

"""## 7. Use the model to translate
Now it's time to put your model into practice! You should run your translation for five randomly sampled English sentences from the dataset. For each sentence, the process is as follows:
* Preprocess and embed the English sentence according to the model requirements.
* Pass the embedded sentence through the encoder to get the encoder hidden and cell states.
* Starting with the special  `"<start>"` token, use this token and the final encoder hidden and cell states to get the one-step prediction from the decoder, as well as the decoder’s updated hidden and cell states.
* Create a loop to get the next step prediction and updated hidden and cell states from the decoder, using the most recent hidden and cell states. Terminate the loop when the `"<end>"` token is emitted, or when the sentence has reached a maximum length.
* Decode the output token sequence into German text and print the English text and the model's German translation.
"""

# Display of random english sentences
eng_sentences = train_sentences[np.array([12, 23, 34, 56, 46])]    
eng_sentences = list(eng_sentences)
eng_sentences

# preprocessing of english sentences
i=0
while i<len(eng_sentences):
    eng_sentences[i] = eng_sentences[i].split(' ')
    eng_sentences[i] = tf.constant(eng_sentences[i], dtype = tf.string)
    eng_sentences[i] = embedding_layer(eng_sentences[i])
    row = eng_sentences[i].numpy().shape[0]
    if row<13:
        zero = tf.zeros((13-row,128))
        eng_sentences[i] = tf.concat([eng_sentences[i], zero], axis = 0)
    elif row>13:
        print('Remove %d index'%i)
        del eng_sentences[i]
        continue
    i+=1

tf.shape(eng_sentences[0])

data = tf.data.Dataset.from_tensor_slices(eng_sentences+eng_sentences+eng_sentences+[eng_sentences[0]]).batch(16, drop_remainder = True)
data.element_spec

# Getting hidden state and cell state using encoder model
hid_state, cell_state = 0,0
for elem in data:
    out1, hid_state, cell_state = encoder(elem)
    print(tf.shape(out1))

start_ind = word_index["<start>"]
end_ind = word_index["<end>"]
ans = [inp]
x = tf.constant([[start_ind]+[0]*13]*16, shape = (16,14))
german_tokens = [[start_ind] for _ in range(5)]
german_tokens

# Using decoder to get german text

i = 0
while i<13:
    out = decoder(x, hid_state, cell_state)
    arr = out.numpy()
    y = x.numpy()
    for j in range(5):
        if german_tokens[j][-1]!=end_ind:
            val = np.argmax(arr[j])
            german_tokens[j].append(val)
            y[j][i+1] = val
    x = tf.constant(y)
    ans.append(inp)
    i+=1

# Display of translation by model

tokenizer.sequences_to_texts(german_tokens)

# Display of actual german sentences

li = [12, 23, 34, 56, 46]
for i in li:
    print(german_sentences[i])

"""# Deployment using Flask"""

!pip install flask-ngrok
!pip install flask

from flask import Flask, request, jsonify, render_template
from flask_ngrok import run_with_ngrok
app = Flask(__name__)
run_with_ngrok(app)   
  
@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict',methods=['POST'])
def predict():
    '''
    For rendering results on HTML GUI
    '''
    english_sentence = [*request.form.values()]
    eng_sentence = list(english_sentence[0].split(' '))
    eng_sentence = tf.constant(eng_sentence, dtype = tf.string)
    eng_sentence = embedding_layer(eng_sentence)
    row = eng_sentence.numpy().shape[0]
    if row<13:
        zero = tf.zeros((13-row,128))
        eng_sentence = tf.concat([eng_sentence, zero], axis = 0)
    elif row>13:
        eng_sentence = list(english_sentence[0].split(' '))[:10]
        eng_sentence = tf.constant(eng_sentence, dtype = tf.string)
        eng_sentence = embedding_layer(eng_sentence)
        row = eng_sentence.numpy().shape[0]
        zero = tf.zeros((13-row,128))
        eng_sentence = tf.concat([eng_sentence, zero], axis = 0)
    
    data = tf.data.Dataset.from_tensor_slices([eng_sentence]*16).batch(16, drop_remainder = True)
    hid_state, cell_state = 0,0
    for elem in data:
        out1, hid_state, cell_state = encoder(elem)
    start_ind = word_index["<start>"]
    end_ind = word_index["<end>"]
    ans = [inp]
    x = tf.constant([[start_ind]+[0]*13]*16, shape = (16,14))
    german_tokens = [[start_ind] for _ in range(5)]
    i = 0
    while i<13:
        out = decoder(x, hid_state, cell_state)
        arr = out.numpy()
        y = x.numpy()
        for j in range(5):
            if german_tokens[j][-1]!=end_ind:
                val = np.argmax(arr[j])
                german_tokens[j].append(val)
                y[j][i+1] = val
        x = tf.constant(y)
        ans.append(inp)
        i+=1

    output = tokenizer.sequences_to_texts(german_tokens)[0][6:]
    final = list(output.split(' '))
    for i in range(len(final)-1):
        if final[i]==final[i+1]:
            break
    output = ' '.join(final[:i])
    return render_template('index.html', prediction_text='German text translation:\n {}'.format(output))


if __name__ == "__main__":
    app.run()

encoder.save_weights("encoder.h5")
decoder.save_weights("decoder.h5")